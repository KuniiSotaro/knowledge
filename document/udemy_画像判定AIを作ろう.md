【画像判定AI自作にチャレンジ！】TensorFlow・Keras・Python・Flaskで作る機械学習アプリ開発入門
==================================================================================

こんにちは！当社でインターンを初めて8ヶ月の國井です。

前回はRuby技術者認定試験のコラムについて書きましたが、今回はAIに挑戦してみました。



## コースを進めて

このコースでは、以下の8つのセクションによって構成されていました。

1. はじめに

1. 環境構築(Python、Anaconda、TensorFlow CPU版のインストール)

1. 【オプション】TensorFlow GPU版のセットアップ(NVIDIA製GPU搭載マシン使用者のみ。非搭載の方はスキップしてください)

1. 画像分類AI自作にチャレンジ

1. データの工夫による精度向上にチャレンジしてみよう

1. 推定プログラムを作成しよう

1. FlaskでWebアプリ化しよう!

1. ボーナスセクション

この中でも、少しつまづいた点について下に載せていきます



### 環境構築

当社ではWindowsを使用しているのですが、私のコンピュータはMacなので、少しインストールに困りました(プログラミングを始めてからずっとそうですが笑)

それは置いといて、実はMacには既にPythonがインストールされています！

ですが、Python2なので、本教材には全く適合しない...

> 後日ですが、Python2とPython3では大幅に変更されている点があるので、
> Python3では動いても、Python2では動かないこともあるそうです

そこで、この教材では`Anaconda`上で実行するとのことでした！

まず、教材では`Anaconda5.0.0`、`Python3.6`でインストールしているのですが、

私が学習した時には`Python3.7`が表示されていたのでそのままインストールしました。

その後ですが、全くライブラリが思うように動いてくれないので仕方なくアンインストール。

結果的に以下のリンクのアーカイブから、教材に適応する`Anaconda`をインストールしました。

> https://repo.continuum.io/archive/

次に、`Anaconda`上で`TensorFlow`という機械学習用のライブラリをインストールします

このライブラリはGoogleがオープンソースで公開しているライブラリのなので、

本音を言うと、機械学習がどのように行われているかを知りません。

そのため、機械学習について、基礎的な部分から学習する必要があると思いました

> Railsチュートリアルでも、初めからログイン・ログアウトの部分をgemに頼らないので...

その後、`TensorFlow`のGPU版のインストールでした。

このGPU版ですが、そもそもGPUと言うものがピンと来なかった自分は、「GUIとCUIのこと？」とか

思ってしまい、なぜインストールできないのかを3時間ほど悩んでいました。

諦めて妹のWindowsのコンピュータでも行いましたが、失敗してしまいました。

結果ですが、Macにも妹のWindowsにもNVIDIA製のGPUが存在しないということで、この章は諦めました。

そもそもGPUはCPUと異なり、単純計算に優れているものだそうで、ゲーム用のコンピュータで多用されているそうです



### 画像分類

作成するアプリケーションでは、「サル」、「イノシシ」、「カラス」のそれぞれ100枚の画像を、

機械学習して、モデル(分類器)を用いて、カメラなどで作成した写真を通して評価する、と言うものです

アプリの開発フローとしては、

1. データの収集・生成

1. データの前処理

1. モデルを定義

1. トレーニング(教師あり学習)

1. テスト

1. 評価

という流れです。


データの収集では、flickrと言う写真がたくさん集まっているサイトから、`urllib`ライブラリを使って写真をダウンロードします(クローリング)

これに関しては、当社でもAPIを頻繁に使用しているので、イメージをすることができました。

ただし、yahooのアカウントが必要とのことなので、用意しておくべきです(米国版)

実際にPythonのコードから写真をダウンロードする際には、ターミナル上での環境を設定する必要があり、

Macでは`source activate [環境名]`と打ち込むことで起動します

また、pythonのコードを書く際に、`from flickrapi import FlickrAPI`などと書かれて、

「全くRubyと違うやん！」とか、コードの最後に`end`が存在しなかったり、Rubyと文法が全く違う

ことに大きく驚いた記憶があります

PythonとRubyは似た者同士とは言われていますが、しっかりと文法も勉強しないといけないですね。

実際に書かれたコードの訳をすると、

1. APIキーの取得

1. 保存フォルダの指定

1. 写真のみをAPIから取得し、フォルダに保存する(クローリング)

と言う流れです

その後、クローリングした写真の中で、関係のない写真を削除することでモデルを作成する際の精度を向上することを目指します

> `download.py`



### データの生成

pillowと呼ばれるpythonの画像を扱うライブラリを使用して、

* PIL：Image

* os：glob(ファイルの一覧)

* numpy：配列を扱う

* scikit-leran：クロスバリデーション(データを分離して学習と評価を行う)

```python
# TensorFlowが扱いやすい形
X = np.array(X)
Y = np.array(Y)
```

* JupiterNotebook：ブラウザ上でコードを実行できる

  => AnacondaNavigatorですでにある

  => `.ipynb`がJupiterNotebookで表示される拡張子

* `np.save`：numpyで学習したデータをファイルで保存する

> `gen_data.py`

> `animal.npy`：学習したデータ



### トレーニングしたデータをテスト・実行

* `Keras`：

  * ニューラルネットワークを使用する際に使用(sequential)

  * 二次元のデータ

  * 活性化関数

  * ドロップアウト

  * データを一次元に変更

  * dense：全結合層

   => 最後の出力層は3層

  * np_utils

* numpy

* `np.load`：ファイルからデータを配列に読み込む

  => 最大値で割ることで、float型に変更されて計算しやすくなる

* `one-hot-bector`：正解値は1、他はゼロ

  => `[0,1,2]`を`[1,0,0]`、`[0,1,0]`、`[0,0,1]`に変更する

  ```python
  np_utils.to_categorical
  ```

* このURLにあるコードを参考にした

https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py

> `def model_train()`

* `Conv2D`を使用

* トレーニング時の最適なアルゴリズム

  ```python
  keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)
  ```

* 損失関数：正解と推定値の誤差

  ```python
  model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
  ```

* モデルの結果を、`model.save`で、`.h5`という拡張子で保存する



### 学習とテストを実行する

* `h5`ファイルは、pipでインストールすることで保存できる

* `GPU`よりも`CPU`の方が学習が遅い



## 推定プログラムを作成する

* コマンドラインから、画像ファイルを与えて推定するプログラムを作る

* 既存モデルをロードする(h5ファイル)

* 推定を行う(`predict.py` 引数に`画像ファイル名`)



1. パッケージのインポート

1. 変数の初期化

1. モデル定義、パラメータのロード

1. 推定処理の実行

* `load_model`を用いて、変数modelを返す

* 一番値の大きい配列の添字を返す(推定)：一番確率が高いものを返す



### Flaskでアプリ化しよう

* Flaskのインストールは、pipで行う

* `werkzeug.utils`：ファイルをチェックする関数(`secure_filename`)、Flaskのモジュール

```
animal_cnn.py
```
