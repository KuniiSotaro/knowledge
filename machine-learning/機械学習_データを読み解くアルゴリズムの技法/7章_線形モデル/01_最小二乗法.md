01 最小二乗法
===========

`回帰問題`：例 $`(x_i,f(x_i))`$ $`(i = 1,\cdots,n)`$ から、推定関数 $`\hat{f}: X \rightarrow \mathbb{R}`$ を学習する



## 1.線形単回帰

`最小二乗法`：$`\sum_{i=1}^n \epsilon_i^2`$ を最小にするような $`\hat{f}`$ を探索する方法

* `残差`：真の関数値と推定された関数値の差 $`\epsilon_i = f(x_i) - \hat{f}(x_i)`$

* `単回帰`：説明変数と目的変数が1つずつでの回帰

  > 1つの`特徴量` $`x_i`$ からなる回帰



### 線形単回帰

> $`(h_i,w_i)`$ ： $`n`$ 組の身長と体重($`1 \leq i \leq n`$)

`線形単回帰`は、方程式 $`w = a + bh`$ を仮定する

* 残差の二乗和 $`\sum_{i=1}^n(w_i -(a+bh_i))^2`$ を最小にするパラメータの $`a`$、$`b`$ の値を選ぶ

* 上式の偏導関数を解き、それらが0になる方程式を、$`a`$ 、$`b`$ について解く(合成関数の微分を用いる)

  > $`\begin{eqnarray}\frac{\partial}{\partial a}\sum_{i=1}^n(w_i-(a+bh_i))^2 = -2 \sum_{i=1}^n(w_i-(a+bh_i)) = 0\end{eqnarray}`$
  >
  > $`\begin{eqnarray}\frac{\partial}{\partial b}\sum_{i=1}^n(w_i-(a+bh_i))^2 = -2 \sum_{i=1}^n(w_i-(a+bh_i))h_i = 0\end{eqnarray}`$

* それぞれの値は、以下で求められる($`\hat{}`$：$`a`$,$`b`$、$`\bar{}`$： $`h_i`$,$`w_i`$(標本平均))

  > $`\begin{eqnarray}\hat{a} = \bar{w} - \hat{b}\bar{h}\end{eqnarray}`$
  >
  > $`\begin{eqnarray}\hat{b} = \frac{\sum_{i=1}^n(h_i - \bar{h})(w_i - \bar{w})}{\sum_{i=1}^n(h_i - \bar{h})^2}\end{eqnarray}`$

* ゆえに、線形回帰による解は、以下の式で表される

  > $`\begin{eqnarray}w = \hat{a} + \hat{b}h = \bar{w}+\hat{b}(h-\bar{h})\end{eqnarray}`$

![体重と身長の線形回帰.png](./images/01_最小二乗法/体重と身長の線形回帰.png)



### 回帰係数の見方

特徴量 $`x`$ と、目的変数 $`y`$ に対して、回帰係数は以下の式で表される

* 分子($`n\sigma_{xy}`$)：$`h`$ と $`w`$ の共分散を $`n`$ 倍したもの

* 分母($`n\sigma_{xx}`$, $`n \sigma_{x}^2`$)：$`h`$ の分散を $`n`$ 倍したもの

  > $`\begin{eqnarray}\hat{b} = \frac{n \sigma_{xy}}{n \sigma_{xx}} = \frac{\sigma_{xy}}{\sigma_{xx}}\end{eqnarray}`$

解釈方法は、以下の通り

* 共分散($`\sigma_{xy}`$)：$`x`$ と $`y`$ の単位の積(kg・cm)

* 分散($`\sigma_{xx}`$)：$`x`$ の単位の平方(cm^2)

これらの商の単位が、$`x`$ の単位当たりの $`y`$ の単位となる(kg/cm)



### 中心化と正規化

**中心化**

$`x`$ の値から $`\hat{x}`$ を引き、$`y`$ の値から $`\hat{y}`$ を引くことで、切片を`0`にすること

> 平行移動は、回帰係数には影響を与えない

**正規化**

$`x`$ を、その分散で割ること

正規化された特徴量と目的変数の共分散が、`回帰係数`$`\hat{b}`$ となる

> $`x_i \rightarrow x_i' = \frac{x_i}{\sigma_{xx}}`$, $`\bar{x} '\rightarrow \bar{x}' = \frac{\bar{x}}{\sigma_{xx}}`$ とする
>
> $`\begin{eqnarray}\hat{b} = \frac{1}{n}\sum_{i=1}^n(x_i' - \bar{x}')(y_i - \bar{y}) = \sigma_{x'y}\end{eqnarray}`$

* 線形単回帰は、以下のステップから構成される

  1. 特徴量を、その分散で割って正規化する

  1. 目的変数と、特徴量の共分散を計算する



### 外れ値の影響

最小二乗解の残差の和は、`0`となる

> $`\begin{eqnarray}\sum_{i=1}^n(y_i - (\hat{a} + \hat{b} x_i)) = n(\bar{y} - \hat{a} - \hat{b}\bar{x}) = 0\end{eqnarray}`$

* ただし、線形回帰が`外れ値`に影響しやすい原因にもなっている

  > `外れ値`：測定の誤差などによって、回帰直線から遠くに位置してしまった点

* 一方で、最小二乗法の機能は、`外れ値`があってもうまく機能する

> 赤矢印に点が移動すると,実線が点線になる

![外れ値あり単回帰](./images/01_最小二乗法/外れ値あり単回帰.png)

**外れ値に対しての最小二乗法の見方**

観測される $`y`$ の値には、ランダムノイズが入っていると仮定する

* 観測された例は、$`(x_i,f(x_i))`$ ではなく、$`(x_i,f(x_i)+\epsilon_i)`$

* この例を用いて、ある $`a`$ と $`b`$ に対して、$`f(x) = a + bx`$　を仮定する

  * $`a`$ と $`b`$ が既知：残差の値が正確に計算できる

  * 分散 $`\sigma^2`$ が既知：残差の集合が得られる確率の推定ができる

> ただし、$`a`$ と $`b`$ は未知であるため、推定しないといけない
>
> 望ましい $`a`$ と $`b`$ の推定値：残差の得られる確率が最大になるような値



### 行列の記法について

* $`\bf{X}`$：列に $`d`$ 個の特徴量、行に $`n`$ 個のインスタンス

  > $`\begin{eqnarray}\bf{X} = \left(\begin{array}{ccc}5 & 0 \\3 & 5 \\1 & 7\end{array}\right)\end{eqnarray}`$

* $`\bf{X}_{r \cdot}`$：$`\bf{X}`$ の第 $`r`$ 行

  > $`\begin{eqnarray}\bf{X}_{1 \cdot} = \left(\begin{array}{ccc}5 & 0\end{array}\right)\end{eqnarray}`$

* $`\bf{X}_{\cdot c}`$：$`\bf{X}`$ の第 $`c`$ 列

  > $`\begin{eqnarray}\bf{X}_{\cdot 1} = \left(\begin{array}{ccc}5 \\3 \\1\end{array}\right)\end{eqnarray}`$

* $`\bf{X}_{r c}`$：$`\bf{X}`$ の $`r`$ 行 $`c`$ 列

  > $`\begin{eqnarray}\bf{X}_{11} = \left(\begin{array}{ccc}5\end{array}\right)\end{eqnarray}`$

* $`\mu_j`$：第 $`j`$ 列の平均

  $`\begin{eqnarray}\mu_j = \frac{1}{n}\sum_{i=1}^n\bf{X}_{ij}\end{eqnarray}`$

  > $`\begin{eqnarray}\mu_1 = \frac{1}{n}\sum_{i=1}^n\bf{X}_{i1}\end{eqnarray} = \frac{5 + 3 + 1}{3} = 3`$

* $`\bf{\mu}^\bf{T}`$：全ての列の平均を含む行ベクトル

  > $`\begin{eqnarray}\bf{\mu}^\bf{T} = \left(\begin{array}{ccc}3 & 4 \end{array}\right)\end{eqnarray}`$

* $`\bf{1}`$：全ての成分が`1`である $`n`$ 次元ベクトル

  > $`\bf{1}= \left(\begin{array}{ccc}1 \\1 \\1\end{array}\right)`$

* $`\bf{1 \mu^T}`$：各行が $`\bf{\mu}^\bf{T}`$ である $`n`$ 行 $`d`$ 列の行列

  > $`\begin{eqnarray}\bf{1 \mu^T} = \left(\begin{array}{ccc}3 & 4 \\3 & 4 \\3 & 4\end{array}\right)\end{eqnarray}`$

* $`\bf{X}' = \bf{X} - \bf{1 \mu^{T}}`$：各列の平均が`0`である`中心化データ行列`

  > $`\begin{eqnarray}\bf{X} - \bf{1 \mu^{T}} \\ = \left(\begin{array}{ccc}5 & 0 \\3 & 5 \\1 & 7\end{array}\right)- \left(\begin{array}{ccc}3 & 4 \\3 & 4 \\3 & 4\end{array}\right) \\=\left(\begin{array}{ccc}2 & -4 \\0 &  1 \\-2 &  3\end{array}\right)\end{eqnarray}`$

* $`\bf{M} = \bf{\mu^T \mu}`$：$`d`$ 行 $`d`$ 列の行列

  > $`\begin{eqnarray}\bf{\mu^T \mu} = \left(\begin{array}{ccc}3 \\4\end{array}\right)\left(\begin{array}{ccc}3 & 4\end{array}\right)\\= \left(\begin{array}{ccc}9 & 12 \\12 & 16\end{array}\right)\end{eqnarray}`$

* $`\bf{S} = \bf{X'^TX'}`$：$`d`$ 行 $`d`$ 列の行列である`散乱行列`

  $`\bf{S} = \bf{X'^TX'} = (\bf{X} - \bf{1 \mu^T})^{\bf{T}}(\bf{X} - \bf{1 \mu^T})\\= \bf{X^T X} - n \bf{M}`$

  > $`\begin{eqnarray}\bf{S} = \left(\begin{array}{ccc}8 & -14 \\-14 &  26\end{array}\right)\end{eqnarray}`$

* $`\bf{\sum} = \frac{1}{n}\bf{S}`$：$`\bf{X}`$ の共分散行列

  > $`\begin{eqnarray}\bf{\sum} =\left(\begin{array}{ccc}\frac{8}{3}   & -\frac{14}{3} \\-\frac{14}{3} &  \frac{26}{3}\end{array}\right)\end{eqnarray}`$

  * $`\sigma_{jc}`$：共分散

    $`\begin{eqnarray}\sigma_{jc} = \frac{1}{n}\sum_{i=1}^n(\bf{X}_{ij} - \mu_j)(\bf{X}_{ic} - \mu_c) = \frac{1}{n}\Bigr( \sum_{i=1}^n \bf{X_{ij}X_{ic}} - \mu_i \mu_c\Bigl)\end{eqnarray}`$

  * $`\sigma_{jj}`$：第 $`j`$ 列の分散

    $`\begin{eqnarray}\sigma_{jj} = \frac{1}{n}\sum_{i=1}^n(\bf{X_{ij} - \mu_j})^2 = \frac{1}{n}\Bigr( \sum_{i=1}^n \bf{X_{ij}^2 - \mu_j^2} \Bigl)\end{eqnarray}`$



## 2.線形重回帰
