07 まとめ
========

* 本章では、ニューラルネットワークの「順方向の伝播」について解説した

* 本章のニューラルネットワークは、パーセプトロンと、ニューロンの信号が階層的に伝わると言う点では同じ

* しかし、次のニューロンへ信号を送信する際に、信号を変化させる活性化関数に大きな違いがあった

  * ニューラルネットワークでは活性化関数が滑らかに変化する`シグモイド関数`

  * パーセプトロンでは信号が急に変化する`ステップ関数`



## まとめ

* ニューラルネットワークでは、活性化関数として`シグモイド関数`や`ReLu関数`のような滑らかに変化する関数を利用する

* NumPyの多次元配列をうまく使うことで、ニューラルネットワークを効率よく実装することができる

* 機械学習の問題は、回帰問題と分類問題に大別できる

* 出力層で使用する活性化関数は

  * 回帰問題：恒等関数

  * 分類問題：ソフトマックス関数

* 分類問題では、出力層のニューロンの数を分類するクラス数に設定する

* 入力データのまとまりをバッチといい、バッチ単位で推論処理を行うことで、計算を高速に行うことができる



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/05/01 |
