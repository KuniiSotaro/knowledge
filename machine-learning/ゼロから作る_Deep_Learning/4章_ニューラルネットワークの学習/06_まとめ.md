06 まとめ
========

* 本章では、ニューラルネットワークの学習を行なった

* 初めに、ニューラルネットワークが学習を行えるようにするために、`損失関数`と言う「指標」を導入した

  * この`損失関数`を基準として、その値が最も小さくなる重みパラメータを探し出すことが、ニューラルネットワークの目標

  * また、出来るだけ小さな`損失関数`の値を探し出すための手法として、`勾配法`と呼ばれる、関数の傾きを使った手法を用いた



## 本章で学んだこと

* 機械学習で使用するデータセットは、訓練データとテストデータに分けて使用する

* 訓練データで学習を行い、学習したモデルの汎化能力をテストデータで評価する

* NNの学習は、損失関数を指標として、損失関数の値が小さくなるように、重みパラメータを更新する

* 重みパラメータを更新する際には、重みパラメータの勾配を利用して、勾配方向に重みの値を更新する作業を繰り返す

* 微小な値を与えた時の差分によって微分を求めることを数値微分と言う

* 数値微分によって、重みパラメータの勾配を求めることができる

* 数値微分による計算には時間がかかるが、その実装は簡単である

  * 一方、`誤差逆伝搬法`は、高速に勾配を求めることができる



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/05/04 |
