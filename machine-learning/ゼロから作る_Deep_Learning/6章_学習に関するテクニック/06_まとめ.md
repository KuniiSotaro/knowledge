06 まとめ
========

* 本章では、ニューラルネットワークの学習を行う上で重要なテクニックを紹介した

  * パラメータの更新方法

  * 重みの初期値の与え方

  * Batch NormalizationやDropout

* また、ここで扱った技術は、最先端のディープラーニングにおいても頻繁に利用される



### 本章で学んだこと

* パラメータの更新方法には、`SGD`の他に、`Momentum`や`AdaGrad`、`Adam`などの手法がある

* 重みの初期値の与え方は、正しい学習を行う上で非常に重要である

* 重みの初期値として、「Xavierの初期値」や「Heの初期値」などが有効である

* `Batch Normalization`を用いることで、学習を速く進めていくことができ、また、初期値に対してロバストになる

* 過学習を抑制するための正則化の技術として、`Weight decay`や`Dropout`がある

* ハイパーパラメータの探索は、良い値が存在する範囲を徐々に絞りながら進めるのが効率の良い方法である



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/05/12 |
