02 交差検証の利点
===============

* `交差検証`には、訓練セットとテストセットをただ分割するよりも良い点がいくつかある

  * まず、`train_test_split`がランダムにデータを分割することを思い出す

  * もし、クラス分類が難しいデータが全て訓練セットに入り、テストセットには簡単なデータしか入らなかったとすると、テストセットに対する精度はありえないほど高くなる

  * もし、クラス分類が大変な例が全てテストセットに入ってしまうと、ありえないほど低いスコアになってしまう

  * `交差検証`を使えば、全てのデータが正確に1度だけテストに用いられる

    * 個々の分割は1度だけテストに用いられるため

    * したがって、モデルはデータセットの全てのサンプルに対して良い汎化性能を示さなければ、交差検証スコアとその平均を高くすることができない

* データを多数に分割すると、モデルの訓練データセットに対する敏感さを知ることができる

  * irisデータセットでは精度が90%から100%まで変動した

  * これはかなり大きい変動だが、これを見ることで、このモデルが最悪の場合と最良の場合にどの程度の性能を示すかがわかる

* `交差検証`のもう1つの利点は、データを単純に分割する場合と比較して、データをより効率的に使えるということ

  * `train_test_split`を用いると、通常75%のデータを訓練に使い、25%を評価に用いる

  * 5分割交差検証の場合には、それぞれの回で4/5(80%)のデータを訓練に用いる

  * 10分割交差検証の場合には、9/10(90%)を訓練に用いる

  * データが多ければ多いほど、モデルは正確になる

* `交差検証`の最大の問題は計算コストである

  * k個のモデルを訓練するため、単純な分割の場合に比べておよそk倍遅くなる

> `交差検証`は新しいデータに適用するためのモデルを作る方法ではない
>
> `交差検証`はモデルを返さない
>
> `cross_val_score`を呼び出すと、内部には複数のモデルが構築される
>
> しかし、`交差検証`の目的は、与えられたアルゴリズムが特定のデータセットに対してどの程度汎化できるかを評価することだけにある



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/03/24 |
