
00 はじめに
=========

* ここまでは、教師あり学習と教師なし学習の基本を学び、様々な機械学習アルゴリズムを見てきた

    * 次は、モデルの評価とパラメータの選択について詳しく見ていく

* ここでは、回帰とクラス分類の教師あり学習について焦点を当てる

    * 教師なし学習の評価やモデル選択は、定性的になってしまうため

* これまで、教師あり学習モデルを評価するためには、`train_test_split`関数を使ってデータセットを訓練セットとテストセットに分割し、

    * 訓練セットに対して`fit`メソッドを呼び出してモデルを構築し、

    * テストセットに対して`score`メソッドを呼び出して評価してきた

* `score`メソッドは、クラス分類に関しては正しくクラス分類されたサンプルの割合を計算する

    * このプロセスの例を見てみる


```python
from sklearn.datasets import make_blobs
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# 合成データセットの生成
X, y = make_blobs(random_state=0)
# dataトラベルを訓練セットとテストセットに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
# モデルのインスタンスを生成し、訓練データで学習
logreg = LogisticRegression().fit(X_train, y_train)
# テストセットでモデルを評価
print("Test set score: {:.2f}".format(logreg.score(X_test, y_test)))
```

    Test set score: 0.88


    /Users/MacUser/anaconda2/envs/tf140/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
      FutureWarning)
    /Users/MacUser/anaconda2/envs/tf140/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.
      "this warning.", FutureWarning)


* データを訓練セットとテストセットに分割するのは、新しく見たことのないデータに対するモデルの**汎化性能**を計測するため

    * 訓練セットに対する適合度には興味がなく、訓練中には見ていないデータに対する予測の精度を見たいため

* ここでは、この評価の2つの側面について深めていく

    * まず、より頑健な汎化性能評価手法である`交差検証`を導入する

    * さらに、`クラス分類性能`と`回帰性能`を評価する手法についても、`score`メソッドで提供されるデフォルトの$R^2$よりも良い方法を議論する

* さらに、教師あり学習モデルに対して、汎化性能が最大になるように効率的にパラメータを調整する手法である`グリッドサーチ`についても述べる



| 版     | 年/月/日   |
| ------ | ---------- |
| 初版   | 2019/03/23 |
| 第二版 | 2019/05/05 |
