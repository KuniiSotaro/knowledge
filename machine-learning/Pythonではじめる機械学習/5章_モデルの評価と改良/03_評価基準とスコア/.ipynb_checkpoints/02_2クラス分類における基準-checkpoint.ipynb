{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 2クラス分類における基準\n",
    "======================\n",
    "\n",
    "* `2クラス分類`は、実用上おそらく最も一般的で、概念的には単純な機械学習アプリケーションである\n",
    "\n",
    "* しかし、このような簡単なタスクでも、評価には様々な注意点がある\n",
    "\n",
    "* 別の基準を見る前に、精度ではうまくいかない場合を見てみる\n",
    "\n",
    "* 2クラス分類の場合には、2つのクラスを`陽性クラス`と`陰性クラス`と呼び、探しているものを`陽性`と呼ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. エラーの種類\n",
    "\n",
    "* 精度が予測性能の尺度として良くない場合がしばしばある\n",
    "\n",
    "    * 間違えた回数には、我々が興味を持つような情報が全ては含まれていないため\n",
    "    \n",
    "    * 自動テストで癌の早期発見のスクリーニングをするアプリケーションを考えてみる\n",
    "    \n",
    "    * テストが陰性であれば患者は健康であ理、陽性であればさらなる検査に回される\n",
    "    \n",
    "    * ここで、テストが陽性の場合(癌であるらしい場合)を`陽性クラス`、陰性の場合を`陰性クラス`と呼ぶ\n",
    "    \n",
    "    * モデルは完璧に機能するわけではないが、間違いは必ず起こる\n",
    "    \n",
    "    * どのようなアプリケーションであっても、間違いの結果が実世界でどのような影響を及ぼすかを考えなくてはならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1つの間違い方は、健康な患者を陽性に分類してしまうこと\n",
    "\n",
    "    * この場合患者は余分な検査を受けることになる\n",
    "    \n",
    "    * この結果、費用と面倒(心理的ストレス)が患者にかかることになる\n",
    "    \n",
    "    * このような間違った陽性との判断を**偽陽性**と呼ぶ\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* もう1つの間違い方は、病気の患者を陰性と分類してしまうこと\n",
    "\n",
    "    * この場合、患者は必要な検査や治療が受けられなくなる\n",
    "    \n",
    "    * 診断されなかった癌は深刻な健康問題を引き起こし、場合によっては死に至る可能性がある\n",
    "    \n",
    "    * このような種類の、誤った陰性との分類を**偽陰性**と呼ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 統計学では、**偽陽性**を`タイプⅠエラー`、**偽陰性**を`タイプⅡエラー`と呼ぶ\n",
    "\n",
    "    * 癌の診断の例では、**偽陰性**を可能な限り避けるべきである"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* これはやや極端な例だが、偽陽性と偽陰性が同じ重みであることはほとんどない\n",
    "\n",
    "    * ビジネスアプリケーションでは、双方のエラーに値段をつけても良い\n",
    "    \n",
    "    * そうすれば、精度の代わりに損失額で評価できる\n",
    "    \n",
    "    * このようにすると、どのモデルを使うかをよりビジネス的に判断することができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 偏ったデータセット\n",
    "\n",
    "* エラーのタイプは、2つのクラスの一方がもう一方よりもずっと多い場合に重要になる\n",
    "\n",
    "    * 実際にはこのような場合は多い\n",
    "    \n",
    "    * 良い例がクリックスルーの場合\n",
    "    \n",
    "    * 個々のデータポイントは、ユーザに提示されたアイテムの「インプレッション」を表す\n",
    "    \n",
    "    * ここでいうアイテムは、広告かもしれないし、関連したページかもしれないし、関連するSNSユーザのフォローかもしれない\n",
    "    \n",
    "* 目的は、あるアイテムをユーザに提示した場合に、ユーザがそれをクリックする(つまり興味を持つ)かどうかを予測すること\n",
    "\n",
    "    * ユーザはインターネット上に提示されたもののほとんどをクリックしない(特に広告)\n",
    "    \n",
    "    * この場合、100本に1本見てくれれば良いので、サンプルの99%が「クリックされない」クラスになってしまう\n",
    "    \n",
    "    * このように一方のクラスが他方のクラスよりもずっと多いようなデータセットを**偏ったデータセット**と呼ぶ\n",
    "    \n",
    "        * 実際には、偏ったデータがほとんどで、頻度が同じだったり近かったりするようなデータは珍しい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* クリック予測で99%の精度を達成するクラス分類器ができたとする\n",
    "\n",
    "    * これは、99%の精度が素晴らしく思えたら、クラスの偏りを考えに入れていないため\n",
    "    \n",
    "    * これは機械学習モデルを構築しなくても、常に「クリックされない」と予測するだけで達成できる\n",
    "    \n",
    "    * 問題は、精度という基準では、常に「クリックされない」と返すモデルと、潜在的には良いモデルを区別できないということ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* この問題をはっきりさせるために、9:1に偏ったデータセットを作る\n",
    "    \n",
    "    * digitsデータセットの数字9を9以外の数字と分割する問題にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `DummyClassifier`を、常に多数のクラス(ここでは「9以外」)を予測するようにして、精度が役に立たないことを確かめてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels: [False]\n",
      "Test score: 0.90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "print(\"Unique predicted labels: {}\".format(np.unique(pred_most_frequent)))\n",
    "print(\"Test score: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 何も学習しなくても90%の精度が得られた\n",
    "\n",
    "     * 一方を常に予測しているだけで90%が達成できてしまう問題もある\n",
    "        \n",
    "     * 実際のクラス分類器と比較してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "pred_tree = tree.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 精度でいうと、`DecisionTreeClassifier`は常に同じ答えを返す予測器よりも少し良い\n",
    "\n",
    "    * これが意味するのは、`DecisionTreeClassifier`の使い方を何か間違えたか、精度が良い基準でないのか、どちらか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 比較のために、あと2つクラス分類器を評価してみる\n",
    "    \n",
    "    * `LogisticRegression`と、デフォルトの`DummyClassifier`\n",
    "    \n",
    "    * デフォルトの`DummyClassifier`は、ランダムに予測を行うが、訓練セットと同じ比率で予測クラスを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy score: 0.79\n",
      "logreg score: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacUser/anaconda2/envs/tf140/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy = DummyClassifier().fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "print(\"dummy score: {:.2f}\".format(dummy.score(X_test, y_test)))\n",
    "\n",
    "logreg = LogisticRegression(C=0.1).fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ランダムな出力を行うダミークラス分類器のスコアが明らかに一番悪く(精度の観点)、`LogisticRegression`のスコアは良い\n",
    "\n",
    "    * しかし、ランダムな分類器ですら80%の精度を達成している(何を参考にすれば良いのかが、分からなくなる)\n",
    "    \n",
    "    * ここでの問題は、偏ったデータに対する予測性能を定量化する基準として、精度は不適切\n",
    "    \n",
    "    * 本章のここ以降では、モデルの選択に役に立つ他の基準を見ていく\n",
    "    \n",
    "* 特に、機械学習のモデルが、「頻度が高いものを返す」だけのクラス分類器`pred_most_frequent`や、ランダムなクラス分類器`pred_dummy`よりどの程度良いのかを示す基準が欲しい\n",
    "\n",
    "    * モデルを評価する基準は、これらの無意味な予測を排除できるものでなければならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  版  |   年/月/日   |\n",
    "|-----|-----------------|\n",
    "|初版|2019/03/25|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
