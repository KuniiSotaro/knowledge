
04 ナイーブベイズクラス分類器
========================

* `ナイーブベイズクラス分類器`：前節で述べた線形モデルによく似たクラス分類器の一族

    * 調練が線形モデルよりもさらに高速なのが特徴
    
    * この速度の代償として、`ナイーブベイズモデル`の汎化性能は、`LogisticRegression`は`LinearSVC`よりもわずかに劣る場合が多い
    
    * 高速の理由は、クラスに対する統計値を個々の特徴量ごとに集めて、パラメータを学習するため
    
    * scikit-learnには、3種のナイーブベイズクラス分類器(`GaussianNB`、`BernoulliNB`、`MultinomialNB`)が実装されている
    
        * `GaussianNB`：任意の連続値データに適用
        
        * `BernoulliNB`：2値データを仮定している
        
        * `MultinomialNB`：カウントデータを仮定している
        
            * `カウントデータ`：個々の特徴量が何らかの整数カウントを表現しているデータ(例：文中に出てくる単語の出現数など)
            
        * `BernoulliNB`や`MultinomialNB`は、ほとんどの場合データのクラス分類に用いられる


* `BernoulliNB`クラス分類器は、個々のクラスに対して、特徴量ごとに非ゼロである場合をカウントする

    * 以下の例で表す


```python
import numpy as np

X = np.array([[0, 1, 0, 1],
                        [1, 0, 1, 1],
                        [0, 0, 0, 1],
                        [1, 0, 1, 0]])
y = np.array([0, 1, 0, 1])
```

* それぞれ4つの2値特徴量を持つ4つのデータポイントがある

    * 2つのクラス0と1がある
    
    * クラス0のデータポイント(最初のと3番目)に対して、最初の特徴量はゼロが2回、非ゼロが0回出てくる
    
    * 2番目の特徴量はゼロが1回、非ゼロが1回である2番目のクラスに対しても同様に計算する
    
* クラスごとに非ゼロの要素をカウントするには、下に示すようにする


```python
counts = {}
for label in np.unique(y):
    # クラスに対してループ
    # それぞれの特徴量ごとに非ゼロの数を(加算で)数える
    counts[label] = X[y == label].sum(axis=0)
print("Feature counts:\n{}".format(counts))
```

    Feature counts:
    {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}


* 残りのナイーブベイズモデル(`Multinomial`、`GaussianNB`)は、計算する統計量が若干異なる

    * `Multinomial`ではクラスごとの、個々の特徴量の平均値を考慮に入れる
    
    * `GaussianNB`では平均値だけでなく標準偏差も格納する

* 予測の際には、個々のクラスの統計量とデータポイントが比較され、最もよく適合したクラスが採用される

    * `MultinomialNB`や`BernoulliNB`では、線形モデルの場合と同じ形の予測式になる
    
    * ナイーブベイズモデルの`coef_`は、線形モデルの場合と若干意味が異なる
    
        * ナイーブベイズモデルの`coef_`は$w$と同じでない

## 1. 利点、欠点、パラメータ

* `MultinomialNB`と`GaussianNB`には、パラメータが1つだけある

    * モデルの複雑さを制御する`alpha`
    
    * 働きとしては、以下のようになる
    
        * アルゴリズムは、全ての特徴量に対して正の値を持つ仮想的なデータポイントが`alpha`の大きさに応じた量だけ追加されたように振る舞う
    
        * アルゴリズムの性能は`alpha`の値に対して比較的頑健である
        
        * つまり、`alpha`の値がアルゴリズムの性能に致命的な違いをもたらすことはない
        
        * しかし、多くの場合この値を調整することで、いくらか精度を上げることができる

* `GaussianNB`は多くの場合、高次元データに対して用いられるが、他の2つはテキストのような疎なカウントデータに対して用いられる

    * 一般に`MultinomialNB`の方が`BernoulliNB`よりも若干性能が良い
    
    * 特に比較的多数の非ゼロ特徴量がある場合(大きなドキュメント)には、`MultinomialNB`が有効
    

* ナイーブベイズモデルの利点と欠点の多くは線形モデルと共通する

    * 訓練も予想も非常に高速で、訓練の過程も理解しやすい
    
    * 高次元の疎なデータに対してもうまく機能するし、パラメータの設定に対しても比較的頑健である
    
    * 線形モデルですら時間がかかりすぎるような大規模なデータセットに対するベースラインとして非常に有用である

|  版  |    年/月/日    |
|-----|------------------|
|初版|2019/03/03|
