{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 特徴量ハッシング\n",
    "================\n",
    "\n",
    "* `ハッシュ関数`：潜在的に無限に広がる値を、有限の$m$種類の値に割り当てる関数\n",
    "\n",
    "    * ここでは、以下の通りに定義する\n",
    "    \n",
    "        *  `ハッシュ値`：ハッシュ関数を適用した後に得られる値\n",
    "        \n",
    "        * `ハッシュテーブル`：ハッシュ値を格納するテーブル\n",
    "        \n",
    "* ハッシュテーブルのサイズは、$m$となる\n",
    "\n",
    "* 入力値の取りうる範囲は出力値の取りうる範囲よりも広いため、値が異なる入力値が同じ出力値に割り当てられることがある\n",
    "\n",
    "    * これを、`衝突`と呼ぶ\n",
    "    \n",
    "* `一様なハッシュ関数`は、ハッシュ値が$m$種類のそれぞれにおおよそ同じ回数だけ割り当てられることを保証する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* イメージとしては、ハッシュ関数は、番号付きボール(キー)を取り込んで$m$個のビン(容器)の1つに割り当てるマシンと捉えることができる\n",
    "\n",
    "    * 同じ番号のボールは、常に同じビンに割り当てられる\n",
    "    \n",
    "    * このような特性により、特徴量の値を有限な範囲内に維持しつつ、機械学習の学習と評価のサイクルに必要となる記憶容量と計算時間を減らす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ハッシュ関数によってキーをビンに割り当てる](./images/ハッシュ関数によってキーをビンに割り当てる.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ハッシュ関数は、数値で置き換えられる任意のオブジェクト(コンピュータに格納できるデータ)に適用できる\n",
    "    \n",
    "    * 例)数値、文字列、複雑な構造データなど"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 非常に多くの特徴量があるとき、特徴ベクトルを保存するには多くの容量が必要となる\n",
    "\n",
    "    * `特徴量ハッシング`は、特徴量IDにハッシュ関数を適用することで、特徴ベクトルを$m$次元のベクトルに圧縮する\n",
    "    \n",
    "    * 例)特徴量が文書内の単語の場合、大量の種類の単語が含まれていても、特徴量ハッシングによって$m$個の特徴量に圧縮できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語特徴量のための特徴量ハッシング\n",
    "def hash_features(word_list, m):\n",
    "    output = [0] * m\n",
    "    for word in word_list:\n",
    "        index = hash_fcn(word) % m\n",
    "        output[index] += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特徴量ハッシングの別のバリエーションは、符号コンポーネントを持っており、ハッシュ値のカウントの加算や減算ができる\n",
    "\n",
    "    * この符号コンポーネントを持つ特徴量ハッシングを適用する前後では、特徴ベクトル間の内積の期待値は変わらないことが知られている\n",
    "    \n",
    "    * つまり、特徴量ハッシングによって大きなバイアスが発生することはない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 符号化特徴量ハッシング\n",
    "def hash_features(word_list, m):\n",
    "    output = [0] * m\n",
    "    for word in word_list:\n",
    "        index = hash_fcn(word) % m\n",
    "        sign_bit = sign_hash(word) % 2\n",
    "        if (sign_bit == 0):\n",
    "            output[index] -= 1\n",
    "        else:\n",
    "            output[index] += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特徴量ハッシング後の内積の値は、元の内積の$O$($\\frac{1}{\\sqrt{m}}$)の範囲内にあることが知られているので、そこから誤差を計算できる\n",
    "\n",
    "    * そして、許容可能な誤差に基づいてハッシュテーブルのサイズ$m$を選択できる\n",
    "    \n",
    "    * ただ、実際には$m$の値は試行錯誤して決定することが多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特徴量ハッシングは、線形モデルやカーネル法など、特徴ベクトルと係数ベクトルの内積を含むモデルに利用できる\n",
    "\n",
    "    * 応用例)迷惑メールフィルタリングにおいて有効\n",
    "    \n",
    "    * 一方で、ターゲティング広告の場合に、予測誤差を許容可能な範囲に収めるためには$m$を数十億のオーダーにする必要がある(容量の節約にならない)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特徴量ハッシングの欠点は、特徴量ハッシング後の特徴量が解釈が難しくなる点\n",
    "\n",
    "* 実際に、Yelpレビューデータセットを例に、scikit-learnの`FeatureHasher`クラスを適用した際の、解釈可能性と記憶容量のトレードオフの関係を示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4618"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 最初の10,000件のレビューを読み込み\n",
    "with open('/Users/kunii.sotaro/Downloads/review.json') as f:\n",
    "    js = []\n",
    "    for i in range(10000):\n",
    "        js.append(json.loads(f.readline()))\n",
    "\n",
    "review_df = pd.DataFrame(js)\n",
    "# mにbusiness_idのユニーク数を代入\n",
    "m = len(review_df['business_id'].unique())\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ujmEBvifdJM6h6RLv4wQIg',\n",
       " 'NZnhc2sEQy3RmzKTZnqtwQ',\n",
       " 'WTqjgwHlXbSFevF32_DJVw',\n",
       " 'ikCg8xy5JIg_NGPx-MSIDA',\n",
       " 'b1b1eb3uo-w561D0ZfCEiQ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "h = FeatureHasher(n_features=m, input_type='string')\n",
    "f = h.transform(review_df['business_id'])\n",
    "\n",
    "# 変換後の特徴量が解釈が困難であることを確認\n",
    "review_df['business_id'].unique().tolist()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our pandas Series, in bytes:  790104\n",
      "Our hashed numpy array, in bytes:  56\n"
     ]
    }
   ],
   "source": [
    "# 変換後の特徴量のストレージサイズが大きく減っていることを確認\n",
    "from sys import getsizeof\n",
    "print('Our pandas Series, in bytes: ', getsizeof(review_df['business_id']))\n",
    "print('Our hashed numpy array, in bytes: ', getsizeof(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特徴量ハッシングを適用すると、容量が小さくなり計算が容易になる反面、直感的な解釈が難しくなることがわかる\n",
    "\n",
    "* 解釈を目的としているデータの探索や視覚化においては、特徴量ハッシングを適用することは好ましくない\n",
    "\n",
    "    * 一方、大規模なデータセットを利用した機械学習においては、直感的な解釈の重要性は低く、特徴量ハッシングの適用するメリットを十分に享受できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 版   | 年/月/日   |\n",
    "| ---- | ---------- |\n",
    "| 初版 | 2019/05/04 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
