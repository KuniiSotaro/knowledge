00 はじめに
==========

* インターネットからデータを自動収集すると、膨大なカテゴリ数を持つカテゴリ変数が生まれる

  * 例)ターゲティング広告や、不正検出などのアプリケーションにおいてこのようなデータは一般的



## ターゲティング広告の例

* ターゲティング広告では、ユーザーと広告のマッチングを行う

* 特徴量として、

  * ユーザーID

  * 広告のWebサイトドメイン

  * 検索クエリ(ハッシュ関数)

  * 現在のページ

  * それらを組み合わせた共起関係(論理積)

* これらはいずれも膨大なカテゴリ数を持つカテゴリ変数

  * このようなカテゴリ変数を取り扱うためには、メモリ効率が良く、かつ正確なモデルを早く学習できるような優れた表現の特徴量にエンコードする必要がある



## 既存方法の分類

既存方法は、次のように分類できる



### 1. 膨大なカテゴリ数を気にせず実行する方法

* 計算が軽いシンプルなモデルを用いて学習する

* 例)大規模な計算機を用いて、線形モデル(ロジスティック回帰、SVM)上でOne-Hotエンコーディングを利用する



### 2. 特徴量を圧縮する方法

圧縮方法には、以下の2つの選択肢がある

1. 特徴量ハッシング：線形モデルによく利用される

1. ビンカウンディング：線形モデルだけでなく、決定木に基づくモデルにおいてもよく利用される



## 実際の例

* Microsoftの検索サイトで利用されている広告エンジンでは、簡単な更新処理を使ってオンライン学習ができる、「ベイズプロビット回帰モデル」が用いられている

  * このモデルには、One-Hotエンコーディングのような二値の特徴量が使われていることが報告されている



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/05/04 |
