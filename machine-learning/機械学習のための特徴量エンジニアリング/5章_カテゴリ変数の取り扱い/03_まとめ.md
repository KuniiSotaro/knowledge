03 まとめ
========

## 通常のOne-Hotエンコーディング

* 容量：`O(n)`をスパースなベクトル形式で保存。`n`はデータ点の数

* 計算量：線形モデルの場合、`O(nk)`となる。`k`はカテゴリの数

* 長所：

  * 実装が簡単

  * 潜在的にもっとも正確

  * オンライン学習が可能

* 短所：

  * 計算が非効率

  * 新しく現れるカテゴリへの対応が難しい

  * 線形モデル以外では利用が難しい

  * 大規模なデータセットに対応するには分散処理が必要



## 特徴量ハッシング

* 容量；`O(n)`をスパースな行列形式で保存。`n`はデータ点の数

* 計算量：線形モデルまたはカーネルモデルの場合、`O(nm)`となる。`m`はハッシュ値のビンの数

* 長所：

  * 実装が簡単

  * モデルの学習コストを下げる

  * 新しいカテゴリへの対応が容易

  * 希少なカテゴリへの対応が容易

  * オンライン学習が可能

* 短所：

  * 線形モデルまたはカーネル法を利用したモデルにのみ適用可能

  * ハッシュ化された特徴量は解釈不可能

  * 制度に関する報告が混在しており、有効性が不明



## ビンカウンティング

* 容量：`O(n+k)`を使用する。各データ点の密な表現に加えて、各カテゴリに対して1つの統計量を保存する必要がある

* 計算量：線形jもでるの場合は`O(n)`となる。決定木などの非線形モデルにも使用可能

* 長所：

  * 学習時の計算負担を最小限に抑える

  * 決定木に基づくモデルにも有効

  * 新しいカテゴリに対応するのが比較的容易

  * バックオフまたは最小カウントスケッチを利用することでレアなカテゴリへの対応が可能

* 短所：

  * 履歴データが必要

  * 統計量の更新が遅延するため、オンライン学習に非常に向いている訳ではない

  * リークが発生しやすい



## まとめ

* どの方法を使用するべきかは、利用したいモデルによって異なる

* 線形モデルは学習コストが安価であるため、One-Hotエンコーディングなどの非圧縮表現を扱うことができる

* 一方、決定木に基づくモデルでは、良い分割のために全特徴量の探索を繰り返し行う必要があるので、ビンカウンティングなどの小さな表現を使う方法に限られる

* 特徴量ハッシングはこれらの2つの方法の中間に存在するが、精度に関する報告が混在しており、有効性は不明



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/05/04 |
