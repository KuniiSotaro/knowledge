05 PCAの考察と限界
================

* 次元削減のために`PCA`を用いる：第何主成分までを使えば良いのか？

  * モデルの結果によってチューニング

  * 一方、計算負荷が高くない方法でヒューリスティックに決めることもできる



## ヒューリスティックな決め方

* 「全体の分散の何%が説明できるか？」という基準を基に、第何主成分までを使うのかを決める

* ![k](https://latex.codecogs.com/gif.latex?k)番目の主成分で説明できる分散は、以下の通り

  * ![sigma_k^2](https://latex.codecogs.com/gif.latex?\sigma_k^2)：![X](https://latex.codecogs.com/gif.latex?\bm{X})の![k](https://latex.codecogs.com/gif.latex?k)番目に大きい特異値の2乗

![k番目の主成分](https://latex.codecogs.com/gif.latex?||\bm{X}\bm{v_k}||^2=||\bm{u_k}\sigma_k||^2=\sigma_k^2)

* `スペクトル`：特異値を![sigma_k^2](https://latex.codecogs.com/gif.latex?\sigma_k^2)の大きい順に並べたもの

  * 従って、いくつの主成分を使うかを決めるためには、データ行列の`スペクトル`を求め、分散が十分大きな値を持つとみなせる閾値を選択する

> **説明される分散の値に基づいて![k](https://latex.codecogs.com/gif.latex?k)を決める**
>
> データの全体の分散の80%を説明するのに十分な主成分の個数を決めるには、以下のように![k](https://latex.codecogs.com/gif.latex?k)を選択
>
> ![分散](https://latex.codecogs.com/gif.latex?\frac{\sum_{i=1}^k\sigma_i^2}{\sum_{i=1}^d\sigma_i^2}\geq&space;0.8)



## データセットの本質的な次元を見極める

* スペクトルに「少数の大きな特異値」と「多数の小さな特異値」が含まれている場合

  * 最も大きい特異値のみを使用、残りを使用しない

  * この場合、使用する特異値の最小値と、残りの特異値の最大値の間に、大きなギャップがあれば良い

* この方法は、スペクトルを可視化してチェックする必要があるため、自動化されたデータ処理パイプラインの一部として実行することはできない



## PCAの批判

### 変換がかなり複雑で、結果を解釈するのが難しい

* 主成分と射影ベクトルは実数値：正負のどちらも取り得る

* 主成分は、本質的には(中心化された)行の線型結合であり、射影された値は列の線型結合

  > 例：株価収益率に対する応用：主成分は株式収益率のある時点での線型結合

* 一体、得られた主成分は何を意味するのか？

  * 学習された主成分について人間が理解できるような形でその理由を説明するのは難しい



### SVDによる計算コストが高い

* ある行列の特異値を全て計算するためには、![n>d](https://latex.codecogs.com/gif.latex?n&space;\geq&space;d)とすると、計算のオーダーは以下のようになる

![O(nd^2+d^3)](https://latex.codecogs.com/gif.latex?O(nd^2&plus;d^3))

* もし![k](https://latex.codecogs.com/gif.latex?k)個の主成分のみが必要であった場合

  * `truncated SVD`(大きい順に指定した個数![k](https://latex.codecogs.com/gif.latex?k)の特異値と特異ベクトルを計算する方法)では、以下の計算コストがかかる

  ![truncated SVD](https://latex.codecogs.com/gif.latex?O((n&plus;d)^2k)=O(n^2k))

  * これは、データや特徴量の数が多い場合には不可能



### 様々な形式で行うことが難しい

* ストリーミング形式(順次流れてくるデータを逐次処理する形式)、バッチ更新形式(順次流れてくるデータをある程度のサイズの塊にまとめて処理する形式)は困難

* アルゴリズムは存在するが、それには精度の低下が伴う

* また、学習データから計算した主成分でテストデータを射影すると、テストデータをうまく表現できないと予想される

  * 実際には、データの分布が変わるたびに主成分を再計算する必要がある



### 生のカウントデータには適用してはいけない

* カウントデータは、大きな外れ値が含まれいることが多い

* `PCA`は特徴量間の線形相関を探すため、異常値に対して非常に脆く、相関や分散を大きく変える可能性がある

> 大きな値のデータを最初に間引くか、TF-IDF、対数変換などのスケーリング変換を適用する



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/05/25 |
