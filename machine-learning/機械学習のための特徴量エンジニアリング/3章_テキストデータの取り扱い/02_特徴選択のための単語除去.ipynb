{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 特徴選択のための単語除去\n",
    "======================\n",
    "\n",
    "* `Bag-of-Words`は文章中に含まれる単語を元に特徴量を生成するが、全ての単語が有用な特徴量となる訳ではない\n",
    "\n",
    "    * そこで、特徴量の数を削減するために、有用な特徴量になりそうにならない単語をあらかじめ削除するという方法が取られる\n",
    "    \n",
    "* ここでは、単語から作られる特徴量に対するフィルタ法について説明する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ストップワードによる単語除去\n",
    "\n",
    "* テキスト分類や情報探索などのタスクでは、文章に対する深い理解を必要としない\n",
    "\n",
    "    * そのため、代名詞、冠詞、前置詞のような、文章の理解によらず一般的に使われる単語を特徴量に加えることにあまり意味はない\n",
    "    \n",
    "    * このような単語は`ストップワード`と呼ばれ、処理の対象外とするのが一般的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pythonの有名な自然言語処理パッケージ`NLTK`には、様々な言語に対して言語学者が定義したストップワードが定義されている\n",
    "\n",
    "    * 例)a, about, above, am, an...\n",
    "    \n",
    "* このリストに含まれるストップワードは、アポストロフィ(')を含み、全て小文字で統一されていることに注意する\n",
    "\n",
    "    * もしトークン化でアポストロフィを区切り文字として使用していた場合、このリストをそのまま利用することはできない\n",
    "    \n",
    "    * また、ストップワードかどうかを判定するコードを書くときに、大文字と小文字を区別していると、ストップワードを認識できない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 頻度に基づく単語除去\n",
    "\n",
    "### 1. 頻出単語の除去\n",
    "\n",
    "* ストップワードを除去することで、不要と思われる特徴量の生成を抑えることができる\n",
    "\n",
    "* しかし、ストップワードのリストは汎用性を目的として作成されているため、特定のコーパス(解析対象となる文書全体)が持つ事情をうまく捉えられない\n",
    "\n",
    "    * 通常は有用な単語でも、特定のコーパスでは有用でない単語が存在する\n",
    "    \n",
    "        * 例)New York TImes における\"New York TImes\"\n",
    "    \n",
    "    * このような単語を見つけ出すために、頻度情報が利用できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 単語の出現頻度を調べることで、コーパスに特有の除去すべき単語を浮き彫りにできる\n",
    "\n",
    "    * 例)以下の表のYelpレビューデータセットにおける頻出単語の上位40個\n",
    "    \n",
    "        * この表には多くのストップワードが含まれる\n",
    "        \n",
    "        * この表のストップワード以外の単語が、コーパスに特有の除去すべき単語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ここにPandasで表を作る\n",
    "## 上位40個数まで"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 頻度に基づく単語除去は実用的で役に立つが、使用する際には上位何個までを除去するかを決める必要がある\n",
    "\n",
    "    * これを見つけるのは難しい問題であり、ほとんどの場合は自動で決定する方法はない\n",
    "    \n",
    "    * また、データセットが変わると再検討する必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. レアな単語の取り扱い\n",
    "\n",
    "* タスクによっては、「レアな単語」を除去する必要がある\n",
    "\n",
    "    * これは、出現頻度の低い単語のこと\n",
    "    \n",
    "    * 本当に使用頻度が少ない単語の場合もあれば、単なるスペルミスの場合もある\n",
    "    \n",
    "    * 機械学習にとって、1つか2つの文書にしか現れない単語はノイズでしかない\n",
    "    \n",
    "* 例)Yelpデータセットにおいて、レビューに基づいて店舗のカテゴリを分類するタスクを考える\n",
    "\n",
    "    * 1つのレビューに\"gobbledygook\"という単語が含まれていたとき、これは分類できない\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* レアな単語が実際のデータセットにどれくらい存在するかを確認する\n",
    "\n",
    "    * Yelpデータセットには約160万件のレビュー文書が含まれる\n",
    "    \n",
    "    * これをスペースと句読点を区切り文字としてトークン化すると、単語数(語彙数)は357,481個となる\n",
    "    \n",
    "    * このうち、1つの文書にしか登場しない単語は189,915個、2つの文書にしか登場しない単語は41,162個となる\n",
    "    \n",
    "        * 合計すると、語彙の60%以上がレアな単語となる(これらは除去する)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* レアな単語は除去する前に、まとめて1つの特徴量として扱うこともできる\n",
    "\n",
    "    * 以下の図に例を示す\n",
    "    \n",
    "    * この図では、\"gobbledygook\"と\"zylophant\"という2つのレアな単語が含まれるテキストを`Bag-of-Words`に変換している\n",
    "    \n",
    "    * その際、レアな単語を1つにまとめてGARBAGEという名前の特徴量としている\n",
    "    \n",
    "    * この方法は、ストップワードや頻度に基づく単語除去と問題なく組み合わせて使用できる\n",
    "    \n",
    "    * 注意点として、コーパス全体のカウント処理が終わるまでどれがレアな単語かわからないため、GARBAGE特徴量を作成する前に、普通の`BoW`を完成させる\n",
    "    \n",
    "![GARBAGE特徴量を利用したBag-of-Words表現](./images/GARBAGE特徴量を利用したBag-of-Words表現.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特徴量(単語)にフォーカスしているが、一方でデータ点にも同様のものが存在する\n",
    "\n",
    "    * 例)Wikipediaダンプデータには不完全な`スタブ`(説明不十分項目)が多く含まれる\n",
    "    \n",
    "    * テキスト文書が非常に短い場合、有益な情報を含まないため、学習モデルにとってノイズとなる\n",
    "    \n",
    "        * そのため、短い文章は学習データから取り除いた方が良い\n",
    "        \n",
    "        * ただし、ツイートのようにもともと短いテキストに対しては、特徴量生成とモデリングに別の手法を使う必要がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ステミング(語幹処理)\n",
    "\n",
    "* トークン化された単語をそのまま使うと、同じ単語の変化形が別の単語としてカウントされてしまうという問題がある\n",
    "\n",
    "    * 例)\"flower\"と\"flowers\"は単数形か複数形かの違いだけなのに、別の単語としてカウントされる\n",
    "    \n",
    "    * 例)\"swimmer\"、\"swim\"は非常に意味が近いのに、異なる単語として識別される\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ステミング`：単語を語幹の形に変換する自然言語処理の技術\n",
    "\n",
    "    * 語学的なルールに基づくものもあれば、統計量に基づくものもある\n",
    "    \n",
    "    * アルゴリズムの中には、品詞タグ付けと見出し語化と呼ばれる語学的ルールが組み込まれているものもある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ほとんどの`ステミングツール`は、英語のみ対応している\n",
    "\n",
    "    * 英語に対するステミングを行うフリーツールとして最も広く使われているのが、Porter Stemmer\n",
    "    \n",
    "* Pythonの`NLTKパッケージ`を使ってPorter Stemmerを実行するコードを下に示す\n",
    "\n",
    "    * ただし、完璧ではない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flower'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "stemmer.stem('flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zero'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('zeroes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stemmer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('stemmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sixti'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('sixties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sixti'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('sixty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ステミング`には計算コストがかかる\n",
    "\n",
    "    * このコストが利益を上回るかどうかはタスクによる\n",
    "    \n",
    "    * また、ステミングを行うことで本当は異なる単語を同じにしてしまうというデメリットもある\n",
    "    \n",
    "    * 例)\"new\"と\"news\"は本来異なる意味"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 版   | 年/月/日   |\n",
    "| ---- | ---------- |\n",
    "| 初版 | 2019/04/21 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
