04 まとめ
=========

* `Bag-of-Words`表現は理解しやすく、計算も容易であり、テキスト分類や情報検索などのタスクに有用

  * ただし、テキストを単語に分解することで失われる情報がある

* `Bag-of-Grams`は `Bag-of-Words`の自然な拡張であり、この問題を部分的に解決する

  * `Bag-of-n-Grams`は理解しやすく、`Bag-of-Words`と同じくらい計算が簡単

  * これは、`Bag-of-Words`よりも大量の特徴量を生み出す

  * これは、特徴量を保存するためのストレージコストだけでなく、モデルの学習とテストにかかる計算コストも増加させる

  * `Bag-of-Words`とデータ点の数は同じまま、特徴空間を非常に大きくスパースする

  * nが大きくなるほどこの傾向は顕著になるが、コストに見合ったモデルの性能改善は望めない

    * したがって、通常はn=2、3までで十分であり、より大きなnグラムを使うことは滅多にない

* `Bag-of-n-Grams`のスパース性とコスト増加に対処する1つの方法は、nグラムから有用なフレーズだけを残すこと

  * これには、自然言語処理の技術である`コロケーション抽出`が使われる

  * 定義では、コロケーションはテキスト中で不連続なトークンとして現れる可能性がある

  * しかし、不連続なコロケーションの探索は、計算コストに比べてそれほどの利益をもたらさない



| 版   | 年/月/日   |
| ---- | ---------- |
| 初版 | 2019/04/21 |
